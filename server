/* Scraping into DB (18.2.5)
 * ========================== */

// Dependencies
var express = require("express");
var mongojs = require("mongojs");
var bodyParser = require("body-parser");

// Require request and cheerio. This makes the scraping possible
var request = require("request");
var cheerio = require("cheerio");


// Initialize Express
var app = express();
var PORT = process.env.PORT || 8000;

app.use(bodyParser.json());
app.use(bodyParser.urlencoded({ extended: true }));
app.use(bodyParser.text());
app.use(bodyParser.json({ type: "application/vnd.api+json" }));


// Static directory
app.use(express.static("./public"));


// Set Handlebars.
var exphbs = require("express-handlebars");

app.engine("handlebars", exphbs({ defaultLayout: "main" }));
app.set("view engine", "handlebars");

// Database configuration
var databaseUrl = "scraper";
var collections = ["scrapedData"];

// Hook mongojs configuration to the db variable
var db = mongojs(databaseUrl, collections);
db.on("error", function(error) {
  console.log("Database Error:", error);
});


// Main route (simple Hello World Message)
app.get("/", function(req, res) {
  res.render("index",{});
});

// Retrieve data from the db
app.get("/all", function(req, res) {
  // Find all results from the scrapedData collection in the db
  db.scrapedData.find({}, function(error, found) {
    // Throw any errors to the console
    if (error) {
      console.log(error);
    }
    // If there are no errors, send the data to the browser as a json
    else {
      res.json(found);
    }
  });
});

// Scrape data from one site and place it into the mongodb db
app.post("/scrape", function(req, res) {
  var scrapeLink = req.body.ebayUrl;

  console.log(scrapeLink);
  // Make a request from ebay
  request(scrapeLink, function(error, response, html) {
    // Load the html body from request into cheerio
    var $ = cheerio.load(html);
    console.log("Here");


    // For each element with a "ListViewInner" Id
    $("li.sresult").each(function(i, element) {
      // Save the text of each link enclosed in the current element

      var ebayHtml = $(this).html();
      console.log(ebayHtml);

      var title = $(this).find("h3").text();
      title = title.replace(/[\n\t\r]/g,"");
      
     
      // Save the href value of each link enclosed in the current element
      var link = $(this).find(".imgWr2").attr("href");
      

      // Save the href value of each link enclosed in the current element
      var image = $(this).find("img").attr("src");
     

      
var itemId = $(this).attr("listingid");
      
      //price = price.replace(/[\n\t\r]/g,"");
      

   var price = $(this).find("li.lvprice.prc:first-child").text();
       price = price.replace(/[\n\t\r]/g,"");
      

      var sold = $(this).find("div.hotness-signal").text();
      sold = sold.replace(/^\s+|\s+$/g,'');
      sold = sold.replace(/[\n\t\r]/g,"");
      

      // If this title element had both a title and a link
      if (title && link && image) {
        // Save the data in the scrapedData db
        db.scrapedData.save({
          title: title,
          link: link,
          image: image,
          price: price,
          itemid: itemId,
          sold: sold,
          html: ebayHtml
        },
        function(error, saved) {
          // If there's an error during this query
          if (error) {
            // Log the error
            console.log(error);
          }
         // Otherwise,
          else {
            // Log the saved data
            console.log(saved);
          }
        });
      }
    });
  });

  // This will send a "Scrape Complete" message to the browser
  db.scrapedData.find({}, function(error, data) {
    // Throw any errors to the console
    if (error) {
      console.log(error);
    }
    // If there are no errors, send the data to the browser as a json
    else {
      //res.json(found);

       console.log(data);
      res.render("found",{data});
    }
  });
});


// Listen on port 3000
app.listen(PORT, function() {
  console.log("App running on port "+ PORT +"!");
});
